{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tkinter import Tk\n",
    "from tkinter.filedialog import askopenfilename\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.mlab as mlab\n",
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import hashlib\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "import seaborn as sns\n",
    "import math\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_flight_data():\n",
    "    csv_path = \"/Users/Victor/Documents/UNI/TFG/ML/database.csv\" #Change this to your own path\n",
    "    \n",
    "    return pd.read_csv(csv_path, delimiter=';', encoding=\"ISO-8859-1\")\n",
    "data_set = load_flight_data()\n",
    "\n",
    "# data_set.info()\n",
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attribute_names):\n",
    "        self.attribute_names = attribute_names\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[self.attribute_names].values\n",
    "    \n",
    "class CustomLabelBinarizer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, sparse_output=False):\n",
    "        self.sparse_output = sparse_output\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        enc = LabelBinarizer(sparse_output=self.sparse_output)\n",
    "        return enc.fit_transform(X)\n",
    "    \n",
    "def display_scores_f1(scores):\n",
    "    print(\"Mean f1:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())\n",
    "    print(\"Best f1: \", scores.max())\n",
    "    \n",
    "def display_scores_recall(scores):\n",
    "    print(\"Mean recall:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())\n",
    "    print(\"Best recall: \", scores.max())\n",
    "\n",
    "def display_scores_precision(scores):\n",
    "    print(\"Mean precision:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())\n",
    "    print(\"Best precision: \", scores.max())\n",
    "\n",
    "def display_scores_accuracy(scores):\n",
    "    print(\"Mean accuracy:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())\n",
    "    print(\"Best accuracy: \", scores.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the scaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "#Label Binarizer + Numerical pipeline\n",
    "\n",
    "lb = LabelBinarizer()\n",
    "num_attribs = ['Initial_time', 'ARP_distance', 'ARP_azimuth',\n",
    "       'Heading', 'Altitude', 'IAS', 'GS', 'Barometric_pressure',\n",
    "       'Wind_direction', 'Wind_variability', 'Wind_speed', 'Visibility',\n",
    "       'European_airlines', 'American_airlines', 'Latam_airlines',\n",
    "       'Other_airlines', 'Day_of_the_week', 'Mix_index']\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "        ('selector', DataFrameSelector(num_attribs)),\n",
    "        ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "    ])\n",
    "\n",
    "kling = data_set.copy()\n",
    "\n",
    "data_set_num_pipeline = num_pipeline.fit_transform(data_set)\n",
    "data_set_num_pipeline = pd.DataFrame(data_set_num_pipeline,index=data_set.index,columns = num_attribs)\n",
    "\n",
    "data_set_wtc_pipeline = lb.fit_transform(data_set['WTC'])\n",
    "data_set_wtc_pipeline = pd.DataFrame(data_set_wtc_pipeline,index=data_set.index,columns = lb.classes_)\n",
    "\n",
    "data_set_rwy_pipeline = lb.fit_transform(data_set['RWY'])\n",
    "data_set_rwy_pipeline = pd.DataFrame(data_set_rwy_pipeline,index=data_set.index,columns = lb.classes_)\n",
    "\n",
    "data_set_labels = pd.DataFrame(data_set[\"Time_to_land\"])\n",
    "frames = [data_set_labels,data_set_num_pipeline,data_set_wtc_pipeline,data_set_rwy_pipeline]\n",
    "data_set_pipeline = pd.concat(frames, axis = 1)\n",
    "data_set_prepared = data_set_pipeline.copy()\n",
    "\n",
    "#Change from time to land to 5 categories\n",
    "\n",
    "'''\n",
    "data_set_prepared.loc[data_set_prepared[\"Time_to_land\"] <= 3447, 'landing_cat'] = 'Very delayed'\n",
    "data_set_prepared.loc[data_set_prepared[\"Time_to_land\"] <= 1538, 'landing_cat'] = 'Delayed'\n",
    "data_set_prepared.loc[data_set_prepared[\"Time_to_land\"] <= 1076, 'landing_cat'] = 'Planned'\n",
    "data_set_prepared.loc[data_set_prepared[\"Time_to_land\"] <= 658, 'landing_cat'] = 'Advanced'\n",
    "data_set_prepared.loc[data_set_prepared[\"Time_to_land\"] <= 565, 'landing_cat'] = 'Very advanced'\n",
    "data_set_prepared.drop(\"Time_to_land\", axis = 1, inplace = True)\n",
    "data_set_prepared[\"landing_cat\"].hist(bins=50)'''\n",
    "\n",
    "\n",
    "#Change from time to land to 3 categories\n",
    "\n",
    "\n",
    "data_set_prepared.loc[data_set_prepared[\"Time_to_land\"] <= 3447, 'landing_cat'] = 'Delayed'\n",
    "data_set_prepared.loc[data_set_prepared[\"Time_to_land\"] <= 1076, 'landing_cat'] = 'Planned'\n",
    "data_set_prepared.loc[data_set_prepared[\"Time_to_land\"] <= 658, 'landing_cat'] = 'Advanced'\n",
    "data_set_prepared.drop(\"Time_to_land\", axis = 1, inplace = True)\n",
    "data_set_prepared[\"landing_cat\"].hist(bins=50)\n",
    "\n",
    "data_set_prepared.info()\n",
    "#data_set_prepared[\"landing_cat\"].value_counts()\n",
    "data_set_prepared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case 1: StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# StratifiedShuffleSplit to generate the training set and the test set\n",
    "\n",
    "data_set_prepared_1 = data_set_prepared.copy()\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=3)\n",
    "for train_index, test_index in sss.split(data_set_prepared_1, data_set_prepared_1[\"landing_cat\"]):\n",
    "    strat_train_set = data_set_prepared_1.loc[train_index]\n",
    "    strat_test_set = data_set_prepared_1.loc[test_index]\n",
    "data_set_train_1 = strat_train_set.copy()\n",
    "data_set_test_1 = strat_test_set.copy()\n",
    "\n",
    "X_train_1 = data_set_train_1[list(data_set_train_1.columns)[0:-1]]\n",
    "Y_train_1 = data_set_train_1[list(data_set_train_1.columns)[27]]\n",
    "X_test_1 = data_set_test_1[list(data_set_test_1.columns)[0:-1]]\n",
    "Y_test_1 = data_set_test_1[list(data_set_test_1.columns)[27]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 1.1: CV no tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train and test set\n",
    "\n",
    "X_train_1_1 = scaler.fit_transform(X_train_1.copy())\n",
    "Y_train_1_1 = Y_train_1.copy()\n",
    "X_test_1_1 = scaler.transform(X_test_1.copy())\n",
    "Y_test_1_1 = Y_test_1.copy()\n",
    "\n",
    "#Defining the classifier\n",
    "\n",
    "MLP_clf = MLPClassifier()\n",
    "\n",
    "#CV for the model\n",
    "\n",
    "scores_varias = cross_validate(MLP_clf, X_train_1_1, Y_train_1_1, scoring = ('accuracy','f1_weighted', 'recall_weighted', 'precision_weighted'), cv = 10, return_train_score = False)\n",
    "\n",
    "#Performance measures\n",
    "\n",
    "f1 = scores_varias['test_f1_weighted']\n",
    "accuracy = scores_varias['test_accuracy']\n",
    "recall = scores_varias['test_recall_weighted']\n",
    "precision = scores_varias['test_precision_weighted']\n",
    "    \n",
    "display_scores_f1(f1)\n",
    "display_scores_accuracy(accuracy)\n",
    "display_scores_recall(recall)\n",
    "display_scores_precision(precision)\n",
    "\n",
    "#Prediction\n",
    "\n",
    "Y_pred_1_1 = cross_val_predict(MLP_clf, X_train_1_1, Y_train_1_1, cv = 10)\n",
    "\n",
    "#Confusion matrix\n",
    "\n",
    "cm = confusion_matrix(Y_train_1_1, Y_pred_1_1)\n",
    "labels = [\"Advanced\",\"Planned\",\"Delayed\"]\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(cm)\n",
    "plt.title('Confusion matrix of the classifier')\n",
    "fig.colorbar(cax)\n",
    "ax.set_xticklabels([''] + labels)\n",
    "ax.set_yticklabels([''] + labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()\n",
    "\n",
    "print(\"Confusion matrix:\", str(cm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 1.2: Grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train and test set\n",
    "\n",
    "X_train_1_2 = scaler.fit_transform(X_train_1.copy())\n",
    "Y_train_1_2 = Y_train_1.copy()\n",
    "X_test_1_2 = scaler.transform(X_test_1.copy())\n",
    "Y_test_1_2 = Y_test_1.copy()\n",
    "\n",
    "param_grid = [\n",
    "        {'hidden_layer_sizes': [50, 75, 100,200], 'activation': ['identity', 'logistic', 'tanh', 'relu'], 'solver': ['lbfgs', 'sgd', 'adam'], 'learning_rate':['constant', 'invscaling', 'adaptive'], 'power_t': [0.3,0.5], 'shuffle': [True,False], 'learning_rate_init': [0.001,0.0005]},\n",
    "            ]\n",
    "\n",
    "MLP_clf = MLPClassifier()\n",
    "grid_search = GridSearchCV(MLP_clf, param_grid, cv=10, scoring='f1_weighted', n_jobs = -1)\n",
    "grid_search.fit(X_train_1_2, Y_train_1_2)\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FirstEstimator = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prediction of the classifier\n",
    "\n",
    "Y_pred_1_2 = grid_search.predict(X_test_1_2)\n",
    "\n",
    "#Metrics\n",
    "\n",
    "print(classification_report(Y_test_1_2,Y_pred_1_2))\n",
    "print(\"Accuracy (%):\", str(metrics.accuracy_score(Y_test_1_2, Y_pred_1_2)))\n",
    "print(\"Precision (%):\", str(metrics.precision_score(Y_test_1_2, Y_pred_1_2, average = 'weighted')))\n",
    "print(\"Recall (%):\", str(metrics.recall_score(Y_test_1_2, Y_pred_1_2, average = 'weighted')))\n",
    "print(\"f1 (%):\", str(metrics.f1_score(Y_test_1_2, Y_pred_1_2, average = 'weighted')))\n",
    "\n",
    "confusion = metrics.confusion_matrix(Y_test_1_2, Y_pred_1_2)\n",
    "print(\"Confusion matrix:\", str(confusion))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 1.3: Random_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train and test set\n",
    "\n",
    "X_train_1_3 = scaler.fit_transform(X_train_1.copy())\n",
    "Y_train_1_3 = Y_train_1.copy()\n",
    "X_test_1_3 = scaler.transform(X_test_1.copy())\n",
    "Y_test_1_3 = Y_test_1.copy()\n",
    "\n",
    "param_distributions = [\n",
    "        {'hidden_layer_sizes': [50, 75, 100,200], 'activation': ['identity', 'logistic', 'tanh', 'relu'], 'solver': ['lbfgs', 'sgd', 'adam'], 'learning_rate':['constant', 'invscaling', 'adaptive'], 'power_t': [0.3,0.5], 'shuffle': [True,False], 'learning_rate_init': [0.001,0.0005]},\n",
    "            ]\n",
    "\n",
    "MLP_clf = MLPClassifier()\n",
    "random_search = RandomizedSearchCV(MLP_clf, param_distributions, cv=10, scoring='f1_weighted', n_jobs = -1, n_iter = 50)\n",
    "random_search.fit(X_train_1_3, Y_train_1_3)\n",
    "random_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SecondEstimator = random_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prediction of the classifier\n",
    "\n",
    "Y_pred_1_3 = grid_search.predict(X_test_1_3)\n",
    "\n",
    "#Metrics\n",
    "\n",
    "print(classification_report(Y_test_1_3,Y_pred_1_3))\n",
    "print(\"Accuracy (%):\", str(metrics.accuracy_score(Y_test_1_3, Y_pred_1_3)))\n",
    "print(\"Precision (%):\", str(metrics.precision_score(Y_test_1_3, Y_pred_1_3, average = 'weighted')))\n",
    "print(\"Recall (%):\", str(metrics.recall_score(Y_test_1_3, Y_pred_1_3, average = 'weighted')))\n",
    "print(\"f1 (%):\", str(metrics.f1_score(Y_test_1_3, Y_pred_1_3, average = 'weighted')))\n",
    "\n",
    "confusion = metrics.confusion_matrix(Y_test_1_3, Y_pred_1_3)\n",
    "print(\"Confusion matrix:\", str(confusion))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case 2: Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set_prepared_2 = data_set_prepared.copy()\n",
    "y_2 = data_set_prepared_2[\"landing_cat\"]\n",
    "data_set_temp_2 = data_set_prepared_2.copy()\n",
    "data_set_temp_2.drop(\"landing_cat\", axis=1, inplace=True)\n",
    "X_2 = data_set_temp_2\n",
    "_set = train_test_split(X_2, y_2, train_size=0.80,test_size=0.20, random_state=42)\n",
    "X_train_2 = _set[0]\n",
    "X_test_2 = _set[1]\n",
    "Y_train_2 = _set[2]\n",
    "Y_test_2 = _set[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 2.1: CV no tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2_1 = scaler.fit_transform(X_train_2.copy())\n",
    "Y_train_2_1 = Y_train_2.copy()\n",
    "X_test_2_1 = scaler.transform(X_test_2.copy())\n",
    "Y_test_2_1 = Y_test_2.copy()\n",
    "\n",
    "#Defining the classifier\n",
    "\n",
    "MLP_clf = MLPClassifier()\n",
    "\n",
    "#CV for the model\n",
    "\n",
    "scores_varias = cross_validate(MLP_clf, X_train_2_1, Y_train_2_1, scoring = ('accuracy','f1_weighted', 'recall_weighted', 'precision_weighted'), cv = 10, return_train_score = False)\n",
    "\n",
    "#Performance measures\n",
    "\n",
    "f1 = scores_varias['test_f1_weighted']\n",
    "accuracy = scores_varias['test_accuracy']\n",
    "recall = scores_varias['test_recall_weighted']\n",
    "precision = scores_varias['test_precision_weighted']\n",
    "    \n",
    "display_scores_f1(f1)\n",
    "display_scores_accuracy(accuracy)\n",
    "display_scores_recall(recall)\n",
    "display_scores_precision(precision)\n",
    "\n",
    "#Prediction\n",
    "\n",
    "Y_pred_2_1 = cross_val_predict(MLP_clf, X_train_2_1, Y_train_2_1, cv = 10)\n",
    "\n",
    "#Confusion matrix\n",
    "\n",
    "cm = confusion_matrix(Y_train_2_1, Y_pred_2_1)\n",
    "labels = [\"Advanced\",\"Planned\",\"Delayed\"]\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(cm)\n",
    "plt.title('Confusion matrix of the classifier')\n",
    "fig.colorbar(cax)\n",
    "ax.set_xticklabels([''] + labels)\n",
    "ax.set_yticklabels([''] + labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()\n",
    "\n",
    "print(\"Confusion matrix:\", str(cm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
