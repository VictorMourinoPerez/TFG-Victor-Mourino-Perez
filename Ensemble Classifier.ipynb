{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tkinter import Tk\n",
    "from tkinter.filedialog import askopenfilename\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.plotting import scatter_matrix\n",
    "import hashlib\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "import seaborn as sns\n",
    "import math\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_flight_data():\n",
    "    csv_path = \"/Users/Victor/Documents/UNI/TFG/ML/database.csv\" #Change this to your own path\n",
    "    \n",
    "    return pd.read_csv(csv_path, delimiter=';', encoding=\"ISO-8859-1\")\n",
    "data_set = load_flight_data()\n",
    "\n",
    "# data_set.info()\n",
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attribute_names):\n",
    "        self.attribute_names = attribute_names\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[self.attribute_names].values\n",
    "    \n",
    "class CustomLabelBinarizer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, sparse_output=False):\n",
    "        self.sparse_output = sparse_output\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        enc = LabelBinarizer(sparse_output=self.sparse_output)\n",
    "        return enc.fit_transform(X)\n",
    "    \n",
    "def display_scores_f1(scores):\n",
    "    print(\"Mean f1:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())\n",
    "    print(\"Best f1: \", scores.max())\n",
    "    \n",
    "def display_scores_recall(scores):\n",
    "    print(\"Mean recall:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())\n",
    "    print(\"Best recall: \", scores.max())\n",
    "\n",
    "def display_scores_precision(scores):\n",
    "    print(\"Mean precision:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())\n",
    "    print(\"Best precision: \", scores.max())\n",
    "\n",
    "def display_scores_accuracy(scores):\n",
    "    print(\"Mean accuracy:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())\n",
    "    print(\"Best accuracy: \", scores.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the scaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "#Label Binarizer + Numerical pipeline\n",
    "\n",
    "lb = LabelBinarizer()\n",
    "num_attribs = ['Initial_time', 'ARP_distance', 'ARP_azimuth',\n",
    "       'Heading', 'Altitude', 'IAS', 'GS', 'Barometric_pressure',\n",
    "       'Wind_direction', 'Wind_variability', 'Wind_speed', 'Visibility',\n",
    "       'European_airlines', 'American_airlines', 'Latam_airlines',\n",
    "       'Other_airlines', 'Day_of_the_week', 'Mix_index']\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "        ('selector', DataFrameSelector(num_attribs)),\n",
    "        ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "    ])\n",
    "\n",
    "kling = data_set.copy()\n",
    "\n",
    "data_set_num_pipeline = num_pipeline.fit_transform(data_set)\n",
    "data_set_num_pipeline = pd.DataFrame(data_set_num_pipeline,index=data_set.index,columns = num_attribs)\n",
    "\n",
    "data_set_wtc_pipeline = lb.fit_transform(data_set['WTC'])\n",
    "data_set_wtc_pipeline = pd.DataFrame(data_set_wtc_pipeline,index=data_set.index,columns = lb.classes_)\n",
    "\n",
    "data_set_rwy_pipeline = lb.fit_transform(data_set['RWY'])\n",
    "data_set_rwy_pipeline = pd.DataFrame(data_set_rwy_pipeline,index=data_set.index,columns = lb.classes_)\n",
    "\n",
    "data_set_labels = pd.DataFrame(data_set[\"Time_to_land\"])\n",
    "frames = [data_set_labels,data_set_num_pipeline,data_set_wtc_pipeline,data_set_rwy_pipeline]\n",
    "data_set_pipeline = pd.concat(frames, axis = 1)\n",
    "data_set_prepared = data_set_pipeline.copy()\n",
    "\n",
    "#Change from time to land to 5 categories\n",
    "\n",
    "'''\n",
    "data_set_prepared.loc[data_set_prepared[\"Time_to_land\"] <= 3447, 'landing_cat'] = 'Very delayed'\n",
    "data_set_prepared.loc[data_set_prepared[\"Time_to_land\"] <= 1538, 'landing_cat'] = 'Delayed'\n",
    "data_set_prepared.loc[data_set_prepared[\"Time_to_land\"] <= 1076, 'landing_cat'] = 'Planned'\n",
    "data_set_prepared.loc[data_set_prepared[\"Time_to_land\"] <= 658, 'landing_cat'] = 'Advanced'\n",
    "data_set_prepared.loc[data_set_prepared[\"Time_to_land\"] <= 565, 'landing_cat'] = 'Very advanced'\n",
    "data_set_prepared.drop(\"Time_to_land\", axis = 1, inplace = True)\n",
    "data_set_prepared[\"landing_cat\"].hist(bins=50)'''\n",
    "\n",
    "\n",
    "#Change from time to land to 3 categories\n",
    "\n",
    "\n",
    "data_set_prepared.loc[data_set_prepared[\"Time_to_land\"] <= 3447, 'landing_cat'] = 'Delayed'\n",
    "data_set_prepared.loc[data_set_prepared[\"Time_to_land\"] <= 1076, 'landing_cat'] = 'Planned'\n",
    "data_set_prepared.loc[data_set_prepared[\"Time_to_land\"] <= 658, 'landing_cat'] = 'Advanced'\n",
    "data_set_prepared.drop(\"Time_to_land\", axis = 1, inplace = True)\n",
    "data_set_prepared[\"landing_cat\"].hist(bins=50)\n",
    "\n",
    "data_set_prepared.info()\n",
    "#data_set_prepared[\"landing_cat\"].value_counts()\n",
    "data_set_prepared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# StratifiedShuffleSplit to generate the training set and the test set\n",
    "data_set_prepared_1_1 = data_set_prepared.copy()\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for train_index, test_index in sss.split(data_set_prepared_1_1, data_set_prepared_1_1[\"landing_cat\"]):\n",
    "    strat_train_set = data_set_prepared_1_1.loc[train_index]\n",
    "    strat_test_set = data_set_prepared_1_1.loc[test_index]\n",
    "data_set_train_1_1 = strat_train_set.copy()\n",
    "data_set_test_1_1 = strat_test_set.copy()\n",
    "#strat_train_set\n",
    "#strat_test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features' importance\n",
    "data_set_train_1_1_1_1 = data_set_train_1_1.copy()\n",
    "data_set_test_1_1_1_1 = data_set_test_1_1.copy()\n",
    "\n",
    "\n",
    "rnd_clf=RandomForestClassifier()\n",
    "log_clf=LogisticRegression()\n",
    "#svm_clf = SVC(class_weight = 'balanced', kernel = 'rbf' ,gamma = 'scale', probability = 'True')\n",
    "kne_clf = KNeighborsClassifier(leaf_size = 1, n_neighbors = 10, weights = 'distance', p = 1)\n",
    "mlp_clf = MLPClassifier()\n",
    "bag_clf = BaggingClassifier(\n",
    "    DecisionTreeClassifier(), n_estimators = 1000,\n",
    "    max_samples = 10000, bootstrap = True, n_jobs = -1, oob_score = True, bootstrap_features = True, max_features = 20)\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators = [('rf', rnd_clf), ('bag',bag_clf)],\n",
    "    voting = 'soft')\n",
    "\n",
    "#('svc', svm_clf), ('lr', log_clf),('kn',kne_clf),('mlp', mlp_clf),\n",
    "\n",
    "\n",
    "X_train_1_1_1_1 = data_set_train_1_1_1_1[list(data_set_train_1_1_1_1.columns)[0:-1]]\n",
    "Y_train_1_1_1_1 = data_set_train_1_1_1_1[list(data_set_train_1_1_1_1.columns)[27]]\n",
    "X_test_1_1_1_1 = data_set_test_1_1_1_1[list(data_set_test_1_1_1_1.columns)[0:-1]]\n",
    "Y_test_1_1_1_1 = data_set_test_1_1_1_1[list(data_set_test_1_1_1_1.columns)[27]]\n",
    "\n",
    "\n",
    "for clf in (rnd_clf, bag_clf, voting_clf):\n",
    "    clf.fit(X_train_1_1_1_1,Y_train_1_1_1_1)\n",
    "    Y_pred_1_1_1_1=clf.predict(X_test_1_1_1_1)\n",
    "    print(clf.__class__.__name__, metrics.accuracy_score(Y_test_1_1_1_1, Y_pred_1_1_1_1))\n",
    "\n",
    "#svm_clf, log_clf,kne_clf, mlp_clf,\n",
    "\n",
    "labels = [\"Advanced\",\"Planned\",\"Delayed\"]\n",
    "cm = metrics.confusion_matrix(Y_test_1_1_1_1, Y_pred_1_1_1_1, labels)\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(cm)\n",
    "plt.title('Confusion matrix of the classifier')\n",
    "fig.colorbar(cax)\n",
    "ax.set_xticklabels([''] + labels)\n",
    "ax.set_yticklabels([''] + labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()\n",
    "\n",
    "print(\"Confusion matrix:\", str(cm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
